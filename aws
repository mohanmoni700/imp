  1  * I have an application, how you will setup a VPC ? what all the components you use ?
	How much servers needed
	how much public and private subnets
	public and private routing tabels
	internet gateway
	nat gateway
	nacl
	security group
============================================================================================================================================
  2  * Where you will set the Route Table ?
	In vpc

============================================================================================================================================
  3  * Services used in AWS ?
	ec2,ebs,iam,cloudwatch,cloudtrail,s3,route53,elb,

============================================================================================================================================
  4  * How can you make any S3 bucket as private ?
	while creating the bucket we can able to check the block all public access

============================================================================================================================================
  5  * Cross region replication ? how you apply it ? will it copy automatically ?
	
	cross region replication it's the configuration of source and destination bucket so the objects will be coppied from one bucket to another bucket in different region
	for that we need to have the source and destination bucket with version control enabled
		and we need to attach the role to s3 bucket with following actions
	
	roles policy for source bucket
		"s3:GetObjectVersionTagging",
                "s3:GetObjectVersionAcl",
                "s3:ListBucket",
                "s3:GetReplicationConfiguration",
                "s3:GetObjectVersion"

	roles policy for destination
		replicateObkect
		replicatetags
		replicatedelete

	Yes it will copy automatically.

============================================================================================================================================

6  * S3 transfer accereration ?
	
	Amazon S3 Transfer Acceleration is a feature that enables faster transfers of files over the internet to and from Amazon S3 buckets. It uses Amazon CloudFront's globally distributed edge locations to accelerate transfers over the public internet.

With S3 Transfer Acceleration, you can achieve faster file uploads and downloads, particularly for large files or over long distances, by reducing the time it takes to transfer data over the public internet. This can be particularly useful for global organizations or for transferring data over unreliable network connections.
============================================================================================================================================

7  * Read replica

In AWS, a read replica is a copy of a source database instance that is asynchronously replicated to a target database instance. The target instance is used for read operations only, while the source instance continues to handle both read and write operations. Read replicas are often used in scenarios where the read traffic to a database is much higher than the write traffic, and scaling the source instance vertically may not be cost-effective or practical.

Read replicas in AWS support several types of databases, including Amazon Aurora, Amazon RDS for MySQL, PostgreSQL, MariaDB, and Oracle. When you create a read replica, the target instance is created from a snapshot of the source instance's data, and then data changes are asynchronously replicated from the source instance to the target instance. The target instance can be located in the same region as the source instance or in a different region, which can be useful for disaster recovery or for serving users in different geographic regions.

Some benefits of using read replicas in AWS include:

Improved performance: Read replicas can offload read traffic from the source instance, which can improve the performance of the source instance and reduce latency for read requests.

Scalability: Read replicas can be used to scale read capacity horizontally without incurring the cost of scaling up the source instance.

High availability: Read replicas can be used to provide high availability for read requests, as they can continue to serve read requests even if the source instance fails or becomes unavailable.

Cost-effective: Read replicas can be created and terminated as needed, which can help reduce costs by only paying for the resources used when they are needed.

In summary, read replicas in AWS are a useful tool for improving performance, scalability, and high availability for read-heavy workloads.



============================================================================================================================================
  8  * Suppose you create Auto scaling group and in launch conf you specify as 3 instances, then the all the 3 instances are running in full capacity ? 

	When you create an Auto Scaling Group (ASG) in AWS and specify a launch configuration that includes three instances, 
	the ASG will launch three instances initially.

	However, whether these instances run at full capacity or not depends on a few factors, such as the specifications of the instances, 
	the workload being run on them, and the configuration of the application or service running on them.

For example, if you launch three instances that have only 1 vCPU and 1 GB of memory each, 
running an application that requires a lot of CPU and memory resources may cause these instances to 
run at full capacity or even become overwhelmed. On the other hand, if you launch three instances that have 4 vCPUs and 16 GB of memory each, 
and run a workload that does not require a lot of resources, these instances may not run at full capacity.

In addition, AWS provides various scaling policies that allow you to automatically adjust the number of instances in an ASG based 
on metrics such as CPU utilization, network traffic, or other custom metrics. If your workload increases, 
these policies can launch additional instances to handle the increased load, while if the workload decreases, 
they can terminate instances to reduce costs.

Therefore, whether the instances in your ASG run at full capacity or not depends on many factors, 
and AWS provides various tools and policies to help you optimize your infrastructure's performance and costs.


============================================================================================================================================
 
 9  * will the applciation fails or  it will be running ? Do you think AWS will provide new instance ?

	By default, Auto Scaling will continue to launch new instances even if the application is not running or is unresponsive. 
This is because Auto Scaling is designed to operate independently of the application and can only adjust the number
 of instances based on the metrics or triggers specified in the Auto Scaling policy.
However, it's important to ensure that your Auto Scaling policy is configured correctly to avoid launching instances unnecessarily 
or causing issues with your application. 
For example, you can configure your Auto Scaling policy to use health checks to monitor the status of your application and
 to stop launching instances if the application is not responding.

============================================================================================================================================
  10 * How to you manage credentials ?

		In AWS, there are different ways to manage credentials depending on your use case and the services you are using. Here are some common methods:

IAM Users: AWS Identity and Access Management (IAM) allows you to create users and groups with specific permissions to access AWS resources. You can create IAM users with programmatic access (access keys) or console access (passwords).

IAM Roles: IAM roles are similar to users, but they don't have permanent credentials. Instead, you can assume a role temporarily to access AWS resources. This can be useful when you want to give access to a third-party service or application without sharing your AWS credentials.

AWS Secrets Manager: Secrets Manager is a service that helps you protect and manage secrets such as passwords, database credentials, and API keys. You can use Secrets Manager to store, rotate, and retrieve credentials for your applications and services.

AWS SSO: AWS Single Sign-On (SSO) is a service that makes it easy to centrally manage access to multiple AWS accounts and business applications. With SSO, you can use your existing credentials (such as Microsoft Active Directory) to access AWS and other cloud applications.

AWS CLI: The AWS Command Line Interface (CLI) is a tool that allows you to interact with AWS services from the command line. You can configure the CLI with your AWS access keys to authenticate and access AWS resources.

Regardless of the method you choose, it's important to follow security best practices such as using strong passwords, rotating credentials regularly, and limiting access to only the resources that are necessary.
 
============================================================================================================================================

11 * If credentials icon is not available? What you will do?

If the credentials icon is not available, it might be because you are not logged in to the account, 
or you do not have the necessary permissions to view or modify the credentials.

Here are some steps you can take to troubleshoot the issue:

Check if you are logged in to the correct account: Make sure you are logged in to the account where the credentials are stored. 
If you have multiple accounts, check if you are logged in to the right one.

Verify your permissions: Check if you have the necessary permissions to view or modify the credentials. 
If you do not have the required permissions, you may need to contact the administrator or owner of the account to grant you access.

Refresh the page: Sometimes, the page may not load correctly due to a temporary glitch or network issue. 
Try refreshing the page to see if the credentials icon appears.

Clear your browser cache: Clearing your browser cache and cookies may help resolve the issue. 
Try clearing your cache and cookies and then log in again to see if the credentials icon appears.

Contact AWS support: If none of the above steps work, you can contact AWS support for further assistance.

In summary, if the credentials icon is not available, you should verify your account login, 
permissions, and refresh the page or clear your browser cache. If the issue persists, you can contact AWS support for further assistance.


============================================================================================================================================



12 * You are working on EC2 and that goes down and how do you resolve this ?


	If an EC2 instance goes down, there are several steps you can take to resolve the issue:

Check the instance status: First, check the status of the instance in the EC2 console. 
If the instance is in the "stopped" state, you can simply start the instance by right-clicking on it and selecting "start". 
If the instance is in the "running" state but is not responding, proceed to the next step.

Check the system logs: Check the system logs to see if there are any error messages or other indicators of what caused the instance to go down. 
You can access the system logs through the EC2 console by selecting the instance and clicking on the "Actions" dropdown menu, 
and then selecting "Get System Log".

Restart the instance: If you are unable to determine the cause of the issue, or if the logs indicate that the issue is not easily fixable, 
you can try restarting the instance. This may help resolve the issue in some cases. 
To restart the instance, right-click on it and select "Instance State", then "Stop". 
Wait a few seconds and then select "Instance State", then "Start".

Launch a new instance: If restarting the instance does not resolve the issue, or if the instance cannot be started, 
you can launch a new instance and migrate any data or applications from the old instance to the new one. To do this, 
create a new EC2 instance from a backup or image of the old instance, attach any necessary volumes or storage, 
and configure the instance to use the same IP address or DNS name as the old instance.

Contact AWS support: If none of the above steps work, or if the issue is more complex, 
you may need to contact AWS support for further assistance. AWS provides support services to help troubleshoot and
 resolve issues with EC2 instances.

In summary, if an EC2 instance goes down, you can try checking the instance status, system logs, and restarting the instance.
 If these steps do not resolve the issue, you can launch a new instance or contact AWS support for further assistance.

============================================================================================================================================


  13 * You want to give a access to a EC2 and you have only pvt key and how do you enable him to access the EC2 ?

		If you want to give someone access to an EC2 instance and you only have the private key, you can create a new user in the instance's operating system and provide the private key to that user. Here are the steps you can follow:

		1.Connect to the EC2 instance using SSH and the private key:
		2.Create a new user by running the following command as the root user:
		3.Set a password for the new user:
		4.Add the new user to the sudoers group so that they can perform administrative tasks:
		5.Copy the private key to the new user's home directory:
		6.Test the new user's SSH access by disconnecting from the EC2 instance and reconnecting using the new user's credentials:
		
============================================================================================================================================
 

 14 * EKS ?




============================================================================================================================================
  15 * VPC ? suppose I have a server, need to download the packages from the internet, but sever should not be accessed directly from outside ? how you can do that
  
In Amazon Web Services (AWS), a Virtual Private Cloud (VPC) is a virtual network that provides a private and isolated section of the AWS Cloud.
 It allows you to launch AWS resources, such as EC2 instances and RDS databases, in a defined virtual network that you have complete control over
, including the ability to configure IP addresses, subnets, and routing tables.

So your server is need to download the packages from the internet but not be accessed directly from outside then we can create an NAT gateway
using public subnet and we need to attach this nat gateway with private route which had private subnet association so in this way we can able to
provide access to the internet without making it access publically.




============================================================================================================================================

16 * 2 AWS accounts, my EC2 of 1 account should talk to my another EC2 ? How ?

	
To allow EC2 instances in one AWS account to communicate with EC2 instances in another AWS account, you can use VPC peering. VPC peering allows you to connect two VPCs (one in each account) together so that instances can communicate with each other as if they were on the same network.
Here are the high-level steps to set up VPC peering between two AWS accounts:

	Create a VPC in each AWS account if you haven't already done so.
	Create a VPC peering connection in the first AWS account and specify the VPC ID of the second AWS account.
	Accept the VPC peering connection in the second AWS account.
	Update the route tables in both VPCs to allow traffic to flow between them.
	Configure the security groups in both VPCs to allow the necessary traffic.
	After completing these steps, instances in both VPCs should be able to communicate with each other using their private IP addresses.

It's important to note that VPC peering is only available between VPCs in the same AWS region, so you'll need to make sure that both VPCs are in the same region. Additionally, you'll need to ensure that there are no overlapping IP addresses between the two VPCs, as this can cause routing issues.
	
 
============================================================================================================================================

 17 * IAM ? I have 10 instances, how do you give access to user for only 5 resources ?
	
	To give a user access to only 5 out of 10 instances, you can use AWS Identity and Access Management (IAM) to create a custom policy that specifies the resources the user is allowed to access.

	Here are the high-level steps to create a custom IAM policy for this scenario:

	Identify the IAM user or group that you want to grant access to.
	Create a custom policy that allows access to the specific resources you want to grant access to. 
	For example, if you want to grant access to only 5 out of 10 instances, 
	you can create a policy that allows access to the specific instance IDs of those 5 instances. 
	The policy can also specify which actions the user is allowed to perform on those instances, such as starting or stopping the instances.
	Attach the custom policy to the IAM user or group that you want to grant access to

============================================================================================================================================
  18 * Cross region Route53 ?
	
	Cross-region Route 53 is a feature of Amazon Route 53,
 which is Amazon's highly available and scalable cloud Domain Name System (DNS) service. It allows you to route traffic to resources that are located in different AWS regions.
	
	With cross-region Route 53, you can create a global DNS infrastructure that can route traffic to your AWS resources located in different regions based 
on latency, health, or geographic location. This means that you can have a global presence for your application, with low latency and high availability, 
by distributing traffic across multiple regions.


============================================================================================================================================

  19 * Health checks in Route53

	Health checks in Amazon Route 53 are a feature that enables you to monitor the health and performance of your resources, such as web servers or load balancers. 
	A health check is a periodic probe of a resource's status, typically conducted at regular intervals, to ensure that it's operating correctly and efficiently.

	Route 53 health checks can be configured to monitor endpoints, such as URLs, IP addresses, or other DNS records, and can be used to determine 
	whether the endpoint is healthy or unhealthy. If an endpoint fails a health check, Route 53 can automatically route traffic to a healthy endpoint, 
	which can help to minimize downtime and improve the availability of your applications.

============================================================================================================================================

  20 * DualStack configuration in Route53
	
	DualStack is a feature of Amazon Route 53 that enables you to use both IPv4 and IPv6 addresses for your resources. 
IPv6 is the next generation of the Internet Protocol (IP) and provides a much larger address space than IPv4, which is the current version of IP.

With DualStack, you can create DNS records that contain both IPv4 and IPv6 addresses for your resources, such as web servers or load balancers. 
When a client queries the DNS records, Route 53 returns both the IPv4 and IPv6 addresses, if available, to the client. The client then selects the appropriate address to use based on its own capabilities and preferences.

To configure DualStack in Route 53, you need to create DNS records for your resources that contain both IPv4 and IPv6 addresses. 
You can do this using the Route 53 console, API, or command line tools. 
When you create the DNS records, you specify the IP addresses for each protocol and Route 53 automatically associates them with the appropriate record sets.

============================================================================================================================================

  21 * what is S3 and why customer choose S3 ?
	
	Amazon S3 (Simple Storage Service) is a cloud-based storage service provided by Amazon Web Services (AWS) that allows users to store and retrieve data from anywhere on the web. S3 provides scalable, secure, durable, and highly available object storage infrastructure that enables customers to store and retrieve any amount of data, at any time, from anywhere.

There are several reasons why customers choose S3:

Scalability: S3 provides virtually unlimited storage capacity, allowing customers to store any amount of data they need without worrying about capacity planning or infrastructure limitations.

Durability: S3 is designed for 99.999999999% durability, meaning that objects stored in S3 are protected against data loss due to hardware failures, natural disasters, or other events.

Accessibility: S3 provides a simple web services interface that enables customers to store and retrieve data from anywhere on the web, making it easy to access data from a variety of applications and services.

Security: S3 provides several features to help customers secure their data, including encryption, access controls, and bucket policies that allow customers to define access permissions at a granular level.

Cost-effective: S3 provides a pay-as-you-go pricing model that allows customers to only pay for the storage they use, without any upfront costs or long-term commitments.

Integration: S3 integrates with a wide range of AWS services and third-party applications, making it easy to build complex data-intensive applications and workflows.

Overall, S3 is a powerful storage service that provides customers with a reliable, scalable, and cost-effective way to store and retrieve any amount of data from anywhere on the web.


============================================================================================================================================


  22 * When the jar is created, how will you push it to S3?
	
	To push a JAR file to Amazon S3, you can use the AWS Management Console, AWS CLI, or AWS SDKs.

	Here are the high-level steps for pushing a JAR file to S3 using AWS CLI:
	
	Install and configure AWS CLI on your local machine or EC2 instance.

	Create an S3 bucket if you haven't already done so.

	Create a folder in the S3 bucket where you want to store the JAR file.

	Use the "aws s3 cp" command to push the JAR file to the S3 bucket and folder. For example, the command might look like this:
		command: aws s3 cp myjar.jar s3://mybucket/myfolder/

	This command copies the "myjar.jar" file to the "myfolder" folder in the "mybucket" S3 bucket.

	Verify that the JAR file was uploaded to S3 by checking the S3 Management Console or running the "aws s3 ls" command.

	Note that you may also want to configure access controls for the S3 bucket and folder to restrict access to the JAR file as needed.


============================================================================================================================================

  23 * dynamoDB





============================================================================================================================================
  24 * vpc architecture

	The VPC (Virtual Private Cloud) architecture in Amazon Web Services (AWS) consists of several key components that work together
 to create a secure and isolated network environment within the AWS cloud. Here is a brief overview of the main components of a VPC architecture:

VPC: A VPC is the primary building block of the AWS networking architecture. 
	It is a virtual network that is logically isolated from other virtual networks in the AWS Cloud. 
	You can think of it as a virtual data center in the cloud.

Subnets: Subnets are logical partitions of a VPC that allow you to isolate resources within the VPC. 
	You can create one or more subnets within a VPC to segment resources into different groups based on their function, 
	security requirements, or other criteria.

Route tables: Route tables are used to define the routing rules for traffic within the VPC. 
	You can create one or more route tables within a VPC and associate them with subnets to control how traffic flows between resources.

Internet Gateway: An Internet Gateway (IGW) is a horizontally scaled, redundant, and highly available VPC component that 
	allows traffic between the VPC and the internet. An IGW enables resources within a VPC to communicate with resources outside the VPC.

Network Access Control Lists: Network Access Control Lists (NACLs) are a set of rules that control 
	inbound and outbound traffic at the subnet level. 
   NACLs act as a firewall for subnets and allow you to restrict or allow traffic based on IP address, protocol, or port number.

Security Groups: Security Groups act as a virtual firewall for individual resources, 
	such as EC2 instances or RDS databases, within a VPC. You can use security groups to control inbound and outbound traffic 
	to and from resources based on IP address, protocol, or port number.

Virtual Private Gateway: A Virtual Private Gateway (VGW) is a device that allows you to establish a secure VPN connection between your 
	on-premises network and your VPC. You can use a VGW to extend your on-premises network to the AWS Cloud.

These components work together to create a secure and isolated network environment within the 
	AWS Cloud that can be customized to fit your specific needs.



============================================================================================================================================

 25 * why we need ELB & how you select which type of loadbalancer suitable for my application.

		Selecting the appropriate type of load balancer for your application depends on several factors such as the type of traffic, the architecture of your application, and the desired level of control and configuration.

Here is a brief overview of the different types of load balancers available on AWS and their characteristics:

Application Load Balancer (ALB): This type of load balancer operates at Layer 7 (the application layer) and is ideal for distributing HTTP/HTTPS traffic. ALBs can route traffic based on advanced request routing rules, support host and path-based routing, and integrate with AWS services such as AWS WAF and AWS Lambda. ALBs also support WebSocket and HTTP/2 traffic.

Network Load Balancer (NLB): This type of load balancer operates at Layer 4 (the transport layer) and is ideal for handling TCP, UDP, and TLS traffic. NLBs can route traffic based on IP protocol data, TCP/UDP port, or source IP, and can handle millions of requests per second with ultra-low latencies.

Classic Load Balancer (CLB): This is the legacy load balancer on AWS and supports both Layer 4 and Layer 7 traffic. CLBs can route traffic based on basic routing rules such as round-robin and session stickiness. However, it lacks some of the advanced features and capabilities of ALBs and NLBs.

When selecting a load balancer for your application, consider the following factors:

Traffic type: Determine the type of traffic that your application receives and whether it is HTTP, HTTPS, TCP, or UDP traffic.

Application architecture: Consider the architecture of your application, whether it is a monolithic or microservices-based architecture, and whether it requires advanced routing rules and features.

Scalability requirements: Determine the expected level of traffic and whether the load balancer can handle the expected load.

Security requirements: Consider whether the load balancer integrates with AWS services such as AWS WAF and AWS Certificate Manager to provide secure and encrypted traffic.

********************************************************************************************************************************************************************************
Overall, ALBs are the recommended load balancer for most HTTP/HTTPS-based applications, 
NLBs are recommended for high-performance, low-latency applications, and CLBs are recommended for legacy applications or for those that do not require advanced features.

*******************************************************************************************************************************************************************************************

============================================================================================================================================

	
  26 * crosszone Loadbalancer
	
	Cross-zone load balancing is a feature of Elastic Load Balancing (ELB) that evenly distributes incoming traffic across all healthy registered instances in all Availability Zones associated with a load balancer.

When this feature is enabled, the ELB will distribute traffic across all healthy instances in all Availability Zones, regardless of which zone the ELB is currently in. This means that if an instance in one zone becomes unhealthy, the ELB will continue to route traffic to healthy instances in other zones.

The cross-zone load balancing feature provides better availability and fault tolerance for applications running on Amazon Web Services (AWS) because it ensures that all healthy instances receive traffic, regardless of their zone. Without cross-zone load balancing, ELB will only distribute traffic to instances in the same Availability Zone as the ELB, which can result in uneven traffic distribution and potentially impact the availability of the application.

By default, cross-zone load balancing is enabled for Application Load Balancers (ALBs) and Network Load Balancers (NLBs) on AWS. For Classic Load Balancers (CLBs), cross-zone load balancing can be enabled or disabled. It is recommended to keep cross-zone load balancing enabled for CLBs as well to ensure optimal application performance and availability.

============================================================================================================================================		
  27 * cloudwatch & cloudtrail

CLOUDWATCH:

Services (AWS) that allows you to monitor resources and applications in the AWS Cloud in real-time. 
	It provides you with metrics, logs, and alarms to help you keep track of the performance and health of your resources and applications,
	 and enables you to take action to resolve issues and optimize performance.

CloudWatch collects and stores metric data, which are time-stamped values that represent the performance of your resources and applications. 
	These metrics can be generated by AWS services, such as EC2 instances and RDS databases, or custom metrics that you define.

In addition to metrics, CloudWatch also collects and stores log data, which are text-based records of events and messages
 generated by resources and applications. You can use CloudWatch Logs to store, monitor, and analyze log data, and to generate insights 
and alerts based on specific patterns or conditions.

CloudWatch also provides you with the ability to set alarms based on metric data, which can trigger automated actions or notifications 
when specific thresholds or conditions are met. For example, you can create an alarm that triggers an action if the CPU utilization 
of an EC2 instance exceeds a certain percentage for a certain period of time.

Some key features of CloudWatch include:

Real-time monitoring: CloudWatch provides you with real-time metrics and logs to help you keep track of 
			the performance and health of your resources and applications.

Customizable dashboards: You can create customizable dashboards to display the metrics and logs that are most important to you.

Automation and notifications: CloudWatch enables you to set alarms based on metric data, and trigger automated actions or notifications
		 when specific thresholds or conditions are met.

Integration with other AWS services: CloudWatch can be integrated with other AWS services, such as EC2, RDS, and Lambda, 
		to provide you with a comprehensive view of your AWS resources and applications.

In summary, CloudWatch is a monitoring and observability service that enables you to monitor and manage the performance and 
	health of your resources and applications in the AWS Cloud, and take action to optimize performance and resolve issues.


CLOUDTRAIL:

CloudTrail is a global service that is enabled by default in all AWS regions. 
It can record activity for multiple AWS accounts and can send the data to multiple S3 buckets or CloudWatch Logs in multiple regions.
 CloudTrail logs are stored in an S3 bucket and can be searched using the S3 inventory feature.

There are 3 types of events it will record
management event
data event
insightfull event

CloudTrail enables you to do the following:

Governance, Risk, and Compliance (GRC) Auditing: You can use CloudTrail to provide an audit trail of activity for compliance and security audits.
				 		It can be used to identify which user made an API call and when, 
						which resource was used, what was the request, and what was the response.

Operational troubleshooting and root-cause analysis: CloudTrail enables you to identify and troubleshoot operational issues within your 
						    AWS environment. You can use the recorded data to identify the source of operational
						 problems or identify the root cause of operational issues.

Security analysis: CloudTrail enables you to detect security threats by providing a comprehensive view of user and resource activity 
		in your AWS account. You can use CloudTrail to monitor and alert on specific activities that indicate a security breach.

Resource Change Tracking: CloudTrail enables you to track the changes to your AWS resources, including who made the changes and 
			when they were made.



============================================================================================================================================
  28 * How many aws account you have managed?
  29 * How many aws account you have managed?
 








============================================================================================================================================

 30 * client has different data centers on different locations. if your client has 50 aws accounts now there is a requirement to establish a connectivity so that the application which is hosted in data centers servers can easily communicate with applications (or) resources which are hosted on different vpc and diff aws accounts so how you are going to establish the connection 

One option is to use AWS Direct Connect, which is a dedicated network connection that provides a high-bandwidth, low-latency link between the data center and AWS. With AWS Direct Connect, the client can establish a private virtual interface (VIF) between the data center and the VPCs in different AWS accounts. This allows for direct, secure connectivity between the on-premises network and the AWS environment.

Another option is to use VPN connections between the on-premises data center and the VPCs in different AWS accounts. This allows for encrypted traffic to flow between the on-premises network and the AWS environment over the public internet.

Additionally, the client can use AWS Transit Gateway, which is a service that simplifies network connectivity between VPCs and VPNs across different AWS accounts. With Transit Gateway, the client can create a central hub that acts as a transit point for all VPC and VPN traffic, which allows for easier management and scaling of the network architecture.

Ultimately, the specific solution will depend on the client's requirements for security, performance, scalability, and cost. It is important to carefully evaluate each option and choose the one that best meets the needs of the client's application and network architecture.


============================================================================================================================================

  31 * customer has 50 (or) 100 odd aws accounts they are looking for a solution so that each and every single vpc can communicate with each other how you are going to establish that connectivity?

To establish connectivity between multiple VPCs across different AWS accounts, there are several options available, depending on the specific requirements of the customer's application and network architecture. Here are some of the common options:

VPC peering: VPC peering allows the customer to connect two VPCs together using a direct network route, which enables the VPCs to communicate with each other as if they were in the same network. VPC peering can be established between VPCs in the same or different AWS accounts.

Transit Gateway: AWS Transit Gateway is a fully-managed service that allows the customer to connect VPCs and VPNs across multiple accounts and regions. With Transit Gateway, the customer can create a central hub that acts as a transit point for all VPC and VPN traffic, which allows for easier management and scaling of the network architecture.

VPN connections: The customer can use VPN connections to establish secure connectivity between VPCs across different AWS accounts. This allows for encrypted traffic to flow between the VPCs over the public internet.

AWS PrivateLink: AWS PrivateLink is a service that enables the customer to access services hosted on other VPCs or AWS services over a private connection. This can be useful for securely accessing services across multiple VPCs in different AWS accounts.

Ultimately, the specific solution will depend on the customer's requirements for security, performance, scalability, and cost. It is important to carefully evaluate each option and choose the one that best meets the needs of the customer's application and network architecture.


============================================================================================================================================


 32 * customer has a physical side production environment (or) workloads are running on aws there is 1 particular Ip/CIDR which 
	is continously hitting their environment multiple times in a day they are suspecting that a malicious activity 
	they are asking you to block any kind of a traffic from a Ip/CIDR how you will going to block them?

To block traffic from a specific IP address or CIDR block, you can use AWS Security Groups and 
	Network ACLs (NACLs) in combination with a Web Application Firewall (WAF) to filter the traffic and deny access.

Here are the steps to block traffic from a specific IP address or CIDR block:

Identify the IP address or CIDR block that is causing the issue.

Create a new Security Group or modify an existing one to block traffic from the IP address or CIDR block. 
You can do this by adding an inbound or outbound rule that denies traffic from the specified IP address or CIDR block.

If you are using a Network ACL, create a new rule to block traffic from the IP address or CIDR block. 
You can do this by adding a rule that denies traffic from the specified IP address or CIDR block.

Implement a WAF to filter the traffic and block requests from the specified IP address or CIDR block. 
You can use AWS WAF to create rules to block traffic from specific IP addresses or CIDR blocks.

Monitor the traffic to ensure that the IP address or CIDR block is no longer able to access your environment.

By using a combination of these security measures, you can effectively block traffic from a specific IP address or CIDR block
and prevent further malicious activity.



============================================================================================================================================

 33 * CIDR for 15 ec2 instances , 2 subnets 1 private and 1 public , write CIDR ranges 


vpc - 10.0.0.0/28
pubsubnet- 10.0.0.0/29
privatesubnet- 10.0.0.8/29



============================================================================================================================================

  34 * you have created one server in a private subnet now you have given the Ip address to me. I am the person who will install some softwares
 	(or) configurations on that server. I am siting infront of my laptop i am complaining you that 
	i am not able to access the machinefrom my laptop how you can resolve it?

For this case i will create an user in public subnet instances and provide him that credentials and tell him to access using this instances 
by ssh so he  can able to access that instances and he can able to download and install software since i have added the NAT gateway to that 
private subnet so he won't get any issue with downloading the packages from internet


============================================================================================================================================

 35 * how you can access a machine without a .pem key?


By default, when you create an Amazon EC2 instance, you are required to specify a .pem key pair for secure SSH access to the instance. 
However, if you don't have access to the .pem key pair, there are a few options available to access the instance.

Reset the key pair: You can reset the key pair associated with your instance through the AWS Management Console or using the AWS CLI. 
This will allow you to specify a new .pem key pair, and then use that key pair to access the instance.

Use session manager: If you have configured AWS Systems Manager Session Manager on your EC2 instance, 
	you can use it to access the instance without a .pem key. Session Manager provides a secure and 
	auditable way to access your instances without the need for SSH keys. You can connect to your instance 
	using the AWS Management Console or the AWS CLI.

Mount the root EBS volume: You can detach the root EBS volume from the instance and attach it to another instance.
	 Once attached, you can mount the volume and access the file system to modify or remove the .pem key pair.
	 After making the necessary changes, you can reattach the volume to the original instance and access it using the new key pair.


============================================================================================================================================

  36 * if you create a transit gateway what exactly you will define in attachments?

	AWS Transit Gateway is a managed service that simplifies the network connectivity between Amazon Virtual Private Clouds (VPCs),
on-premises networks, and other cloud resources. It acts as a hub-and-spoke architecture that enables you to connect your VPCs and 
other resources to your Transit Gateway, and route traffic between them in a centralized and efficient way.

	Transit Gateway provides a scalable and highly available solution that allows you to easily manage network connectivity across 
multiple accounts and regions. It supports VPN, Direct Connect, and Transit Gateway Peering connections, enabling you to establish 
secure and private network connections between your VPCs and your on-premises resources.


When you create a Transit Gateway in AWS, you need to define the attachments, which are the connections between your Transit Gateway and your network resources such as VPCs or VPN connections. The attachments are defined in the following way:

Define the attachment type: You need to specify the type of attachment you want to create. You can choose from several attachment types including VPC, VPN, Direct Connect, and Transit Gateway Peering.

Specify the attachment details: Depending on the attachment type you choose, you need to provide the necessary details for the attachment. For example, if you are attaching a VPC, you need to specify the VPC ID and the subnet(s) in which the Transit Gateway will be connected.

Define the routing: Once you have defined the attachment, you need to specify the routing rules that will be used to route traffic between the attachment and the Transit Gateway. You can use the AWS Management Console, CLI or APIs to define the routing.

Configure security: You can also configure security settings for your attachments using security groups and Network Access Control Lists (NACLs).

By defining the attachments in this way, you can create a hub-and-spoke architecture that enables you to connect your VPCs and other resources to your Transit Gateway, and route traffic between them in a centralized and efficient way. This simplifies network management, reduces operational costs, and enhances security and compliance.

============================================================================================================================================

37 * how your sharing the key  for a group of 4 members & these 4 members will be logged in from same username 
after 4/5 days customer complaining that a file deleted how can you track back who did what?

If you have shared a key with a group of 4 members who log in from the same username, it may be difficult to track back who did what if a file was deleted. However, there are a few steps you can take to improve accountability and traceability:

Use individual user accounts: Instead of sharing a single username, create individual user accounts for each member of the group. This way, each user can log in using their own credentials, and their actions can be tracked and audited individually.

Enable logging and auditing: Enable logging and auditing for the system and the file in question. This will allow you to review the logs and identify who accessed the file and when.

Use version control: If the file in question is a document or code file, consider using version control software such as Git. This will allow you to track changes to the file, who made the changes, and when they were made.

Educate users: Educate the users on the importance of security and accountability. Make sure they understand the potential consequences of unauthorized access or data tampering, and encourage them to report any suspicious activity.

By taking these steps, you can improve accountability and traceability, and minimize the risk of unauthorized access or data tampering.


============================================================================================================================================

 38 * what instances you are using in your project? why particular those instances?

We were using Compute-optimized instances in our project because we mainly working on high performance web server so for this case these
types of instances are very helpfull since they are highly optimized instances and they do well with high performance web servers

we are using c6i.16xlarge
	64 cource of cpu
	128 gb of ram


============================================================================================================================================

  39 * customer is asking you to change the instances family to 2 ec2 instances which are part of the autoscalling groups siting on a 
load balancer & the condition is they are not looking for new instances and none of the instances to be deleted how your going to 
change the instance family of these 2 instances?

	To change the instance family of the two EC2 instances without creating new instances or deleting any existing ones, 
you can follow these steps:

Stop the instances: First, stop the two instances that you want to change the instance family for. 
This will ensure that any running processes or services are gracefully terminated and that no data is lost.

Change the instance family: After the instances have been stopped, modify the instance type to the desired family type. 
This can be done by selecting the instances from the EC2 console, clicking on the "Actions" button, and selecting "Instance Settings" 
and then "Change Instance Type". Select the new instance family type from the dropdown menu and click "Apply".

Update the autoscaling group: Once the instance type has been changed, update the autoscaling group to reflect the new instance family type.
 This can be done by selecting the autoscaling group from the EC2 console, clicking on the "Edit" button, 
and modifying the launch configuration to use the new instance family type. Make sure to save the changes.

Start the instances: After the autoscaling group has been updated, start the two instances that were stopped in step 1.
 The instances will now be launched using the new instance family type.

By following these steps, you can change the instance family of the two EC2 instances without creating new instances or 
deleting any existing ones, and ensure that the autoscaling group is updated to use the new instance family type.

============================================================================================================================================

 40 * what kind of individual contribution load that you have played in your experiance on aws? 
what kind of issues you have resolved? what kind of troubleshooting you have performed?












============================================================================================================================================

  41 * pre signed url in s3?

	A pre-signed URL in Amazon S3 is a URL that allows anyone who receives the URL to perform a specific action on an S3 object, 
such as downloading an object or uploading a file to a specific bucket. 
The pre-signed URL is generated using your AWS credentials and includes an expiration time, after which the URL is no longer valid.

The primary use case for pre-signed URLs is to provide temporary access to private objects in S3 to clients that do not have AWS credentials.
 For example, you may want to provide a pre-signed URL to a third-party vendor so that they can upload files to your S3 bucket for a 
limited period of time, without giving them permanent access to your AWS resources.

To create a pre-signed URL, you can use the AWS SDK or AWS CLI, and specify the S3 bucket name, object key, 
and the action you want to allow, such as GET or PUT. You can also specify an expiration time, 
after which the pre-signed URL will be invalid. Once the URL is generated, you can provide it to the client who needs temporary access to the S3
 object.

Using pre-signed URLs, you can control access to your S3 objects more securely and with more flexibility than 
simply making them publicly accessible.


============================================================================================================================================

 42 * different routing policies in aws? which policy you have used for your project?

There are several routing policies available in AWS Route 53, which include:

Simple routing policy: This is the default routing policy and is used when you have a single resource that performs a given function.

Weighted routing policy: This policy allows you to route traffic to multiple resources in proportions that you specify.

Latency-based routing policy: This policy is used when you have resources in multiple AWS regions and want to route traffic to the region
			 with the lowest latency.

Failover routing policy: This policy is used when you have a primary and a secondary resource and want to route traffic
			 to the secondary resource only if the primary resource is unavailable.

Geolocation routing policy: This policy is used when you want to route traffic to resources based on the geographic location of the request.

Multivalue answer routing policy: This policy is used when you want to respond to DNS queries with a list of potential IP addresses
				 for a given resource.

The routing policy used in a project will depend on the specific requirements of the application and infrastructure.
 In my experience, I have used the weighted routing policy to balance traffic between multiple EC2 instances and the latency-based routing
 policy to route traffic to resources in different AWS regions based on the lowest latency.


============================================================================================================================================

43 * diff b/w cname and alias?


In summary, CNAME records are used to map one domain name to another domain name, 
while Alias records are used to map a domain name to an AWS resource. 
Alias records can be used for the domain's apex record, while CNAME records cannot.

CNAME: A CNAME (Canonical Name) record is used to create an alias for a domain name. 
It maps one domain name to another domain name. 
For example, if you have a domain name www.example.com and you want to map it to another domain name, such as www.example.net, 
you can create a CNAME record for www.example.com that points to www.example.net. 
However, CNAME records cannot be used for the domain's apex record, such as example.com, as they cannot coexist with other record types, 
such as MX, NS, SOA, and others.

Alias: An Alias record is also used to create an alias for a domain name, but it can be used for the domain's apex record. 
It maps a domain name to an AWS resource, such as an Amazon S3 bucket, an Elastic Load Balancer, or an Amazon CloudFront distribution. 
Alias records are preferred over CNAME records because they provide better performance and can be used for the domain's apex record.


============================================================================================================================================

44 * what record used for dns to ip?

The A record maps a domain name to one or more IPv4 addresses. When a user enters a domain name in their web browser, 
the browser sends a DNS query to a DNS resolver to look up the IP address associated with the domain name. 
The resolver looks up the A record for the domain name and returns the IP address to the browser, 
which can then connect to the server at that IP address.

It's worth noting that there is also a similar record called AAAA (or "quad-A") record,
 which is used to map a domain name to one or more IPv6 addresses.

============================================================================================================================================

  45 * any experiance with lambda? any experiance inwriting lambda functions?

AWS Lambda is a serverless compute service provided by Amazon Web Services (AWS). 
It enables users to run code without provisioning or managing servers, and pay only for the compute time consumed by the code.

With AWS Lambda, users can upload their code as a function and configure it to trigger automatically in response to specific events, 
such as changes to data in Amazon S3, updates to a DynamoDB table, or API Gateway requests. 
The Lambda service takes care of automatically scaling the resources required to run the code in response to the incoming request volume.

Lambda supports several programming languages including Node.js, Python, Java, C#, Go, and Ruby. 
It also provides integration with other AWS services, making it easy to build serverless applications 
that take advantage of services like S3, DynamoDB, API Gateway, and others.

Lambda functions can be created, edited, and managed through the AWS Management Console, AWS CLI, or programmatically using the AWS SDKs.


============================================================================================================================================


  46 * what is API gateway why we need it ?


AWS API Gateway is a fully managed service that makes it easy for developers to create, publish, monitor, and secure APIs at any scale.
 It allows users to create RESTful APIs that can integrate with other AWS services, as well as external services.

API Gateway provides several benefits, including:

Simplified API creation: API Gateway allows users to easily create RESTful APIs by defining the endpoints, methods, request/response bodies, 
and integrations with backend services using a simple web interface.

Scalability: API Gateway automatically scales to handle any amount of traffic, so developers don't have to worry about provisioning and 
managing servers to handle the load.

Integration with AWS services: API Gateway can integrate with other AWS services such as Lambda, 
S3, and DynamoDB, allowing developers to build powerful APIs that can take advantage of these services.

Security: API Gateway provides several mechanisms to secure APIs, including authentication, authorization, and encryption.

Monitoring and logging: API Gateway provides detailed monitoring and logging of API usage, 
allowing developers to track and analyze traffic patterns, troubleshoot issues, and optimize API performance.

Overall, API Gateway is a powerful tool for building and managing APIs that can integrate with other AWS services and external systems,
 providing a scalable and secure way to expose backend services to external clients.


============================================================================================================================================

  47 * How you bind role to account ( script explain)

Open the AWS Management Console and navigate to the IAM dashboard.
Click on "Roles" in the left-hand navigation menu.
Click the "Create role" button.
Select the type of trusted entity for the role. This can be an AWS service or a third-party identity provider.
Choose the permissions to grant to the role. You can either select an existing policy or create a custom policy.
Give the role a name and optionally a description.
Review your settings and click "Create role".
Once the role is created, you can assign it to an AWS resource by specifying the role ARN (Amazon Resource Name) when creating or updating the resource.
Keep in mind that the specific steps for assigning a role to an AWS resource will vary depending on the type of resource you are working with.


-----also we can able to create that with script--------

aws iam create-role --role-name MyEC2Role --assume-role-policy-document file://trust-policy.json

aws iam attach-role-policy --role-name MyEC2Role --policy-arn arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess

aws ec2 associate-iam-instance-profile --instance-id i-1234567890abcdef --iam-instance-profile Name=MyEC2Role


============================================================================================================================================

  48 * how you configure autoscaling and cloud load balancer

To configure autoscaling and a cloud load balancer in AWS, follow these steps:

Create a launch configuration: A launch configuration is a template that describes the EC2 instance type, AMI, security group, and other details of your instances.
 To create a launch configuration, go to the EC2 dashboard, select "Launch Configurations," and follow the prompts.

Create an auto scaling group: An auto scaling group allows you to automatically add or remove instances based on traffic demand. 
To create an auto scaling group, go to the EC2 dashboard, select "Auto Scaling Groups," and follow the prompts. 
Specify the launch configuration you created in step 1.

Create a load balancer: A load balancer distributes incoming traffic across multiple instances. 
To create a load balancer, go to the EC2 dashboard, select "Load Balancers," and follow the prompts.
Choose the appropriate protocol, port, and security settings for your application.

Add instances to the load balancer: Once your instances are up and running in the auto scaling group, 
you need to add them to the load balancer. To do this, go to the load balancer dashboard, select your load balancer, 
and choose "Add Instance." Select the instances you want to add and click "Register Instances."

Test your setup: To make sure your autoscaling and load balancing configuration is working correctly, test your application by 
accessing it through the load balancer's DNS name. You should see traffic being distributed across the instances in the auto scaling group.

By following these steps, you can create a scalable and highly available application environment 
in AWS using autoscaling and a cloud load balancer.

============================================================================================================================================

  49 * Where your application is running EC2 or EKS










============================================================================================================================================

  50 * Why your team went manual instead of using EKS













============================================================================================================================================
  51 * Security group  ,nacl 

Security groups and network access control lists (NACLs) are two types of network security mechanisms in AWS 
that control inbound and outbound traffic to resources.

A security group acts as a virtual firewall for your instance to control inbound and outbound traffic. 
It is associated with an instance or a network interface and can be customized to control access to specific ports and protocols.

On the other hand, a network access control list (NACL) is an additional layer of security that acts as a firewall for subnets in a VPC. 
It controls inbound and outbound traffic at the subnet level and provides granular control over IP traffic.

The main difference between security groups and NACLs is their scope and the level of control they provide. 
Security groups operate at the instance level, while NACLs operate at the subnet level. 
Security groups provide more granular control over traffic, allowing you to specify the protocol, port, and source/destination IP addresses, 
while NACLs are less granular and only allow you to control traffic based on IP addresses and port numbers

============================================================================================================================================

52 * Ecs










============================================================================================================================================ 
 
 53 * Ec2 s3 iam roles

Creating an EC2 Instance:

Go to the EC2 console.
Click on the "Launch Instance" button.
Select the AMI and Instance type as per your requirement.
Configure the instance details and storage.
Configure the security group and add rules as required.
Review and Launch the instance.
Creating an S3 Bucket:

Go to the S3 console.
Click on the "Create Bucket" button.
Enter a unique name for the bucket.
Select the Region for the bucket.
Configure the settings as per your requirement.
Review and Create the bucket.
Creating an IAM Role:

Go to the IAM console.
Click on the "Roles" option.
Click on the "Create Role" button.
Select the service that will use the role, in this case, select EC2.
Attach the required policies to the role.
Review and Create the role.
After creating the IAM role, you can attach it to the EC2 instance to allow the instance to access the S3 bucket. 
You can do this by following these steps:

Go to the EC2 console.
Select the instance that you want to attach the IAM role to.
Click on the "Actions" button.
Select "Instance Settings" and then click on "Attach/Replace IAM Role".
Select the IAM role that you want to attach to the instance.
Click on "Apply" and the IAM role will be attached to the instance.
Once the IAM role is attached to the instance, you can use AWS CLI or SDK to access the S3 bucket from the
 EC2 instance without explicitly providing the access key and secret key.


============================================================================================================================================

  54 * Lambda 

AWS Lambda is a serverless compute service provided by Amazon Web Services (AWS). 
It enables users to run code without provisioning or managing servers, and pay only for the compute time consumed by the code.

With AWS Lambda, users can upload their code as a function and configure it to trigger automatically in response to specific events, 
such as changes to data in Amazon S3, updates to a DynamoDB table, or API Gateway requests. 
The Lambda service takes care of automatically scaling the resources required to run the code in response to the incoming request volume.

Lambda supports several programming languages including Node.js, Python, Java, C#, Go, and Ruby. 
It also provides integration with other AWS services, making it easy to build serverless applications 
that take advantage of services like S3, DynamoDB, API Gateway, and others.

Lambda functions can be created, edited, and managed through the AWS Management Console, AWS CLI, or programmatically using the AWS SDKs.

============================================================================================================================================
 
 55 * aws instances 

In AWS, an instance refers to a virtual server in the cloud. 
It is a single unit of computing resources like CPU, memory, storage, and networking capacity. 
Users can launch and terminate instances as per their requirement and only pay for the resources consumed by the instances.
AWS offers a wide range of instance types optimized for different workloads such as general-purpose, 
compute-optimized, memory-optimized, storage-optimized, and GPU instances. Each instance type has different characteristics like CPU, memory, network performance, and storage capacity. AWS instances are widely used to run various applications, host websites, process big data, and perform machine learning tasks, among others.

============================================================================================================================================
 
 56 * difference between nat instance and nat gateway

NAT (Network Address Translation) instance and NAT gateway are two options in AWS that allow resources in a private subnet to 
access the internet or other resources outside the VPC.

The main differences between NAT instance and NAT gateway are as follows:

Managed Service: NAT Gateway is a fully managed service by AWS, whereas NAT instance is a self-managed EC2 instance that is 
		configured to perform NAT.

Scalability: NAT Gateway scales automatically up to 45 Gbps of network bandwidth,
	    whereas NAT instance's bandwidth is limited to the instance size and network performance.

High Availability: NAT Gateway is highly available and redundant by default across multiple availability zones, 
		whereas NAT instance requires additional configuration for high availability.

Security: NAT Gateway does not have a public IP and is therefore more secure compared to NAT instance,
	which requires a public IP to access the internet.

Cost: NAT Gateway is a bit more expensive than NAT instance, but it provides more availability, scalability, and better network performance.

In summary, NAT Gateway is a recommended solution for most use cases because of its fully managed, 
highly available, and scalable nature, whereas NAT instance can be used for small workloads or for customized network configurations.


============================================================================================================================================

  57 * loadBalencer

In AWS, a load balancer is a service that distributes incoming network traffic across multiple servers or instances to 
improve the overall performance, availability, and fault tolerance of applications. 
It acts as a single point of contact for clients and routes traffic to healthy backend instances that are registered with the load balancer.

There are three types of load balancers in AWS:

Application Load Balancer (ALB): It works at the application layer (Layer 7) and routes traffic based on the content of the request.

Network Load Balancer (NLB): It works at the transport layer (Layer 4) and routes traffic based on IP protocol data.

Gateway Load Balancer (GWLB) : GWLB operates at the network layer (Layer 3) and can route traffic between multiple VPCs, 
			       Availability Zones, and on-premises networks. It supports protocols like TCP, UDP, and TLS,
			       and can handle up to 50 Gbps of traffic. GWLB can also integrate with other AWS services like CloudWatch, CloudTrail,
			       and AWS Identity and Access Management (IAM).


Classic Load Balancer (CLB): It works at both the transport and application layers (Layer 4 and 7) and routes traffic based on 
			    either the IP protocol data or the content of the request.

Load balancers also perform health checks to monitor the status of backend instances and automatically remove them if they fail. 
They also support SSL termination and provide access logs for monitoring and troubleshooting purposes.

============================================================================================================================================

  58 * aws VPC components

AWS VPC (Virtual Private Cloud) is a virtual network that enables you to launch AWS resources into a virtual network. 
Some of the main components of a VPC include:

Subnets: A subnet is a range of IP addresses within the VPC. You can launch instances in a subnet and control 
inbound and outbound traffic with network access control lists (NACLs) and security groups.

Route tables: A route table contains a set of rules called routes that are used to determine where network traffic is directed.
 Each subnet is associated with a route table, which controls the traffic flow for the subnet.

Internet Gateway: An internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows
 communication between instances in your VPC and the internet.

NAT Gateway: A NAT (Network Address Translation) gateway is a highly available AWS-managed service that 
enables instances in a private subnet to connect to the internet or other AWS services, but prevents the internet from 
initiating connections with those instances.

VPN connection: A VPN (Virtual Private Network) connection is a secure and encrypted connection between your on-premises network 
and your VPC over the internet.

Peering connection: A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between 
them using private IP addresses.

Security Groups: A security group acts as a virtual firewall that controls inbound and outbound traffic for one or more instances.

Network ACLs: Network ACLs act as a firewall for controlling traffic in and out of subnets.
 They are stateless and can allow or deny traffic based on source/destination IP addresses, ports, and protocols.


============================================================================================================================================

 59 * what are the DB you are going to use 60 * about lamda

there are several databases that can be used with AWS Lambda, such as Amazon DynamoDB, Amazon Aurora Serverless, and Amazon RDS Proxy.
 These databases can be used to store and retrieve data in serverless applications built with AWS Lambda.


============================================================================================================================================
  
  61 * difference between network lb and application lb


Network Load Balancer (NLB) and Application Load Balancer (ALB) are two types of load balancers available in Amazon Web Services (AWS). 
Here are the differences between them:

Layer 4 vs. Layer 7: NLB operates at the transport layer (Layer 4) of the OSI model, while ALB operates at the application layer (Layer 7).
This means that NLB is responsible for distributing traffic based on IP addresses and port numbers, 
while ALB can inspect the content of the requests and route them based on rules.

Protocol support: NLB supports TCP, UDP, and TLS protocols, while ALB supports HTTP, HTTPS, and WebSocket protocols.

Health checks: NLB performs health checks on targets by sending TCP or UDP packets to the specified port,
		 while ALB performs health checks at the application layer by sending HTTP or HTTPS requests to a specified path.

Routing capabilities: ALB provides advanced routing capabilities, such as path-based routing, host-based routing,
		 and redirecting to different URLs, while NLB only supports simple routing based on IP addresses and port numbers.

Cross-zone balancing: ALB supports cross-zone load balancing, which distributes traffic evenly across all available
			instances in all Availability Zones, while NLB does not support this feature.

In summary, NLB is suitable for TCP/UDP-based traffic and provides basic load balancing capabilities, 
while ALB is suitable for HTTP/HTTPS-based traffic and provides more advanced load balancing capabilities.

============================================================================================================================================

 62 * about Route 53


Route 53 is a highly available and scalable cloud-based Domain Name System (DNS) web service provided by Amazon Web Services (AWS).
 It is used to route internet traffic to web applications and resources hosted in AWS or outside of AWS.

Some of the key features of Route 53 include:

Domain registration: Route 53 enables users to register domain names and manage the domain registration process.

DNS management: Route 53 allows users to create and manage DNS records, such as A records, CNAME records, and MX records.
	 It also provides advanced features like health checks and failover routing.

Traffic routing: Route 53 can be used to route traffic to different resources based on various factors, 
		such as geolocation, latency, weighted routing, and failover routing.

Integration with AWS services: Route 53 integrates with other AWS services, such as Elastic Load Balancing, Amazon S3,
			 and AWS CloudFront, to enable users to route traffic to these services.

Security and compliance: Route 53 provides features like DNSSEC (DNS Security Extensions), which helps to protect against DNS spoofing
			 and other attacks, and is compliant with various security standards, such as HIPAA and PCI DSS.

Overall, Route 53 is a powerful DNS service that enables users to manage their DNS infrastructure in a scalable and cost-effective way, 
		while also providing advanced features for routing internet traffic.

============================================================================================================================================

  63 * about autoscalling

Autoscaling in Amazon Web Services (AWS) is a feature that allows users to automatically adjust the number of EC2 instances
 running in their environment based on the actual demand.

Here are the main components of AWS autoscaling:

Auto Scaling groups: An Auto Scaling group is a logical grouping of EC2 instances that share the same configuration and scaling policies. 
			Users can define the minimum and maximum number of instances to be running at any given time, 
			and Autoscaling will automatically add or remove instances based on the actual demand.

Launch configurations: A launch configuration is a template that specifies the configuration of the EC2 instances launched
			 by the Autoscaling group, including the AMI, instance type, security groups, and user data.

Scaling policies: Scaling policies define the rules that determine when additional instances should be added or removed
		 from the Autoscaling group. Users can define scaling policies based on various factors, 
		such as CPU utilization, network traffic, or custom metrics.

Health checks: Autoscaling can monitor the health of the instances in the group and replace any instances that fail a health check.

Integration with other AWS services: Autoscaling can be integrated with other AWS services, such as Elastic Load Balancing,
				 to enable automatic scaling of the load balancer based on the actual demand.

Overall, Autoscaling in AWS helps users to ensure that their applications can handle sudden spikes in traffic, 
without incurring unnecessary costs during periods of low demand. It also provides a highly available and scalable
 infrastructure for running applications in the cloud.

============================================================================================================================================

  64 * how to use terraform in AWS











============================================================================================================================================
  65 * how will you restric inbound traffic when outbound traffic in open

To restrict inbound traffic when outbound traffic is open, you can use security groups in Amazon Web Services (AWS). 
A security group acts as a virtual firewall that controls the inbound and outbound traffic for your AWS instances.

Here are the steps to restrict inbound traffic when outbound traffic is open using security groups:

Identify the security group associated with the EC2 instances that require restricted inbound traffic.

Create a new security group and configure it to allow the desired outbound traffic.

In the new security group, create a new inbound rule that allows traffic only from the original security group 
associated with the EC2 instances. This rule should allow traffic only on the specific ports and protocols required by your application.

Remove any other inbound rules from the new security group.

By doing this, you are allowing outbound traffic to flow freely from the EC2 instances while restricting 
inbound traffic to only the ports and protocols required by your application, and only from the original
security group associated with the instances.

It is important to note that security groups are stateful, which means that any traffic that is allowed to 
flow out of an instance is automatically allowed to flow back in, regardless of any inbound rules that may be in place.

============================================================================================================================================

  66 * what is vpc and vpc perring

Amazon Virtual Private Cloud (VPC) is a virtual network service provided by Amazon Web Services (AWS) that allows users to 
create a logically isolated network in the AWS Cloud. Users can create their own VPC and customize the IP address range, subnets, 
and route tables.

VPC peering is a feature that allows users to connect two or more VPCs and route traffic between them using private IP addresses. 
VPC peering enables users to create a virtual network that spans multiple AWS regions or accounts.

Here are some of the benefits of using VPC peering:

Simplified network architecture: VPC peering enables users to create a simplified network architecture that spans multiple VPCs.
 This can help to reduce the complexity of managing multiple VPCs and improve the overall network performance.

Increased security: VPC peering enables users to route traffic between VPCs using private IP addresses,
 which helps to increase the security of the network. Additionally, VPC peering does not require any internet gateway or NAT gateway,
 which can further improve the security of the network.

Cost-effective: VPC peering allows users to connect VPCs using the AWS backbone network, 
which can be more cost-effective than using a VPN connection over the internet.

High availability: VPC peering can help to improve the availability of the network by enabling users to route 
traffic between VPCs across multiple Availability Zones within the same AWS region.

Overall, VPC peering is a powerful feature that enables users to create a flexible and scalable network architecture
 that spans multiple VPCs, while also providing increased security and cost-effectiveness.


============================================================================================================================================


 67 * How will an instance present in Oregon can access a S3 bucket present in Sydney without any manual intervention?
   * (only the ec2 shd b able to access the S3 without any user involved in it,)

To allow an EC2 instance in Oregon to access an S3 bucket in Sydney without any manual intervention, 
you can use Amazon S3 Transfer Acceleration.

Amazon S3 Transfer Acceleration is a feature of Amazon S3 that enables faster transfer of files over the internet 
by using Amazon CloudFront's globally distributed edge locations.

Here are the steps to set up Amazon S3 Transfer Acceleration for an S3 bucket:

Enable Amazon S3 Transfer Acceleration on the S3 bucket that you want to access from the Oregon region. 
This can be done in the AWS Management Console or using the AWS CLI.

Update the endpoint URL for the S3 bucket in your application code or configuration. 
The endpoint URL for an S3 bucket with Transfer Acceleration enabled will have a "s3-accelerate" prefix added to the standard S3 endpoint URL.

Ensure that the EC2 instance in Oregon has internet access and can reach the Amazon S3 Transfer Acceleration endpoint.
 You can do this by configuring the security group associated with the instance to allow outbound traffic to the required ports and protocols.

Once you have set up Amazon S3 Transfer Acceleration and updated the endpoint URL in your application code or configuration, 
the EC2 instance in Oregon should be able to access the S3 bucket in Sydney without any manual intervention. 
The traffic will automatically be routed over the AWS global network through the nearest CloudFront edge location
 to the instance in Oregon, providing faster and more reliable transfer of data.

============================================================================================================================================


 69 * One ALB with 2 instances A and B and ALB is mapped with 2 website site1 and site2,
  70 * Can we configure requests which comes to site1 mapped to instance A n site2 to instance B.
  71 * Can we achieve this behaviour using ALB?


for this I will set the path based load balancer so if the user try to access one website for that website i will attach the target group with 
the instance which I want to use

============================================================================================================================================




  72 * I have one S3 bucket in which im going to upload 3 files, one with 2TB, 4.9TB and 5.1TB.
  	* So how many files will get uploaded into S3 bucket?

only 3 files will be uploaded in s3 bucket
but when the time uploading the file with 5.1 TB it uses the multipart upload process by default s3 bucket can only able to upload with 5tb
as a part.




============================================================================================================================================
  74 * I have 10 ec2 with ALB, each of the instance have 100GB EBS vol. One instance memory utilisation has crossed 80% 
     * and manager asked u to increase the vol to 1TB with zero downtime for all instances, how will u do that?
	Increase EBS Volume Size in AWS
	-----------------------------------------------------------
	Step 1: Take Snapshot of EBS Volume (to be Safe).
	Step 2: Increase EBS Volume Size in AWS Console.
	Step 3: Extend a Linux file system after resizing a volume.


	Command to Extend the file system:
	----------------------------------------------------------------
	df -hT

	Check whether the volume has a partition:
	sudo lsblk

	Extend the partition:
	sudo growpart /dev/xvda 1

Extend the file system on /:
[XFS file system]: sudo xfs_growfs -d /
[Ext4 file system]: sudo resize2fs /dev/xvda1



============================================================================================================================================
  76 * In RDS, we have parameter group and an option group, whats the diff?







============================================================================================================================================
 
 77 * I have 2 subnets in VPC, how can I know which subnet is public?
	
	so I will check routing tabel which is assoicated with subnets and if any routing tabel is associated with internet gateway
then we consider those subnets as public


============================================================================================================================================

  78 * There is a public IP and u have to restrict all type of access for this publicIp, how will u do that?

I can able to define that security group of that instance so I will deny all the inbound traffic to instance so no one can able to access


  
============================================================================================================================================
79 * How does S3 bucket talk to NAT Gateway?

	S3 buckets are accessed over the internet, while NAT Gateway is used to provide internet access to resources in private subnets
 within a VPC (Virtual Private Cloud) in AWS.

When an S3 bucket is accessed from a resource in a private subnet, the traffic goes through the VPC's routing table, 
which has a default route pointing to the NAT Gateway. 
The NAT Gateway then performs Network Address Translation (NAT) and sends the traffic to the internet.

To enable the S3 bucket to talk to the NAT Gateway, you need to configure the VPC's routing table to have a route for the S3 bucket's
 IP address range to the NAT Gateway. This ensures that the traffic from the S3 bucket is sent to the NAT Gateway for 
further processing and routing to the internet.

Additionally, you may need to configure the security group rules for the S3 bucket to allow incoming traffic 
from the private subnet's IP range, and the security group rules for the NAT Gateway to allow outgoing traffic to the S3 bucket's IP range.
		
	It's worth noting that the use of NAT Gateway to provide internet access to resources in private subnets is not required for 
accessing S3 buckets, as S3 buckets can be accessed directly over the internet without the need for NAT Gateway. 
However, if you have resources in a private subnet that need to access the internet for other purposes, 
such as downloading software updates or accessing third-party APIs, then NAT Gateway can be a useful tool for providing internet 
access while still maintaining the security of your private resources.



============================================================================================================================================

  80 * Which AWS service will be best suited for persistent vol for a specific pod in a cluster which wil b catering 10000 requests.
		For persistent volumes for a specific pod in a cluster that will be catering to 10,000 requests, AWS offers a few options:

Amazon Elastic Block Store (EBS) - EBS is a block storage service that provides persistent storage for EC2 instances. 
				   You can use EBS volumes to store data for your containerized applications. 
				  EBS volumes can be attached to an EC2 instance and mounted to a specific directory within a container. 
				EBS volumes are highly available and durable, making them a good choice for production workloads that require high levels of data durability.

Amazon Elastic File System (EFS) - EFS is a scalable, fully managed file system that can be used to provide persistent storage for containers. 
				You can mount an EFS file system to your containers and store your application data in it. 
				EFS provides a file system interface, making it easy to share data between multiple containers running on different EC2 instances.

Amazon S3 - S3 is an object storage service that can be used to store and retrieve any amount of data. 
		You can use S3 to store data for your containerized applications. S3 is highly durable and can provide high levels of availability. 
	However, S3 does not provide a file system interface, so you will need to use an S3-compatible file system interface to mount S3 to your containers.

Amazon FSx for Lustre - FSx for Lustre is a fully managed file system that is optimized for compute-intensive workloads. 
			You can use FSx for Lustre to store data for your containerized applications.
			 FSx for Lustre is designed for high performance and can provide low latency access to data. 
			However, FSx for Lustre is not recommended for applications that require high levels of data durability.

Choosing the best option depends on your specific requirements and the characteristics of your workload. EBS and EFS are both good choices for production workloads that require high levels of data durability and availability, while S3 and FSx for Lustre are better suited for specific use cases that require high performance or specialized features.
 

============================================================================================================================================

81 * Data shd b accessible at all point of time? S3 or EBS or EFS drive


If you need to store large amounts of infrequently accessed data, S3 is the best option. 
If you need low-latency access to data and require persistent storage volumes for individual EC2 instances, EBS is the best option. 
If you need to share files across multiple EC2 instances, EFS is the best option.



============================================================================================================================================

82 * How will migrate the app from onprime to AWS Cloud

Migrating an application from on-premises to AWS Cloud can be a complex process, but here are some general steps to get you started:

Assess your application and its dependencies: Before starting the migration, you should perform a comprehensive assessment of your
application and its dependencies. This should include identifying any interdependencies with other systems,
understanding the performance and resource requirements of the application, 
and determining the best deployment architecture for your application on AWS.

Set up your AWS environment: Once you have assessed your application, you will need to set up your AWS environment. 
This includes creating a Virtual Private Cloud (VPC), configuring networking, and setting up security groups.

Choose your compute resources: Choose the appropriate compute resources on AWS, such as EC2 instances, 
containers, or serverless functions, based on the performance and resource requirements of your application.

Set up your storage: Determine the appropriate storage services to use for your application's data, 
such as Amazon S3 for object storage or Amazon EBS for block storage.

Migrate your application: Migrate your application code and data to AWS. This can be done using tools such as AWS Snowball, 
AWS Migration Hub, and AWS Database Migration Service.

Test and verify your application: Test your application on AWS to ensure that it is running as expected. 
This should include testing for performance, functionality, and scalability.

Switch over to production: Once you have successfully tested your application, you can switch over to production on AWS. 
This involves configuring your DNS records to point to your new AWS environment, updating your load balancers, 
and ensuring that all traffic is flowing to AWS.

Monitor and optimize: Monitor your application's performance and usage on AWS to identify any areas for optimization or improvement. 
This should include setting up monitoring and alerting, and making use of AWS services 
such as Amazon CloudWatch to gain insight into your application's performance.

Overall, migrating an application from on-premises to AWS Cloud requires careful planning, execution, and testing to 
ensure a successful migration. AWS offers a variety of tools and services to simplify the migration process and ensure a smooth transition to the cloud.

============================================================================================================================================

  83 * Suppose I have multiple accounts and need to create AWS infrastructure? How can I do that

		AWS CloudFormation StackSets: AWS CloudFormation StackSets is a service that allows you to deploy CloudFormation stacks 
across multiple AWS accounts and regions. You can create a StackSet and specify the accounts and regions where you want to deploy the stack.
 This can help you create consistent infrastructure across multiple accounts, and simplify management and updates.

============================================================================================================================================

  84 * Which type of instances are using in AWS

We are using optimized compute instances




=========================================================================================================================================

  85 * There is surge in traffic how you will maintain frontend and backend?

If there is a surge in traffic to your frontend and backend, there are several steps you can take to maintain availability and performance. 
Here are some suggestions:

Scaling: You can scale your infrastructure horizontally by adding more instances or servers to handle the increased traffic. 
For example, you can use AWS Auto Scaling to automatically add or remove instances based on the demand.

Caching: You can use caching to improve the performance of your application. 
For example, you can use a content delivery network (CDN) to cache static content such as images and videos, 
or use a caching service such as Amazon ElastiCache to cache frequently accessed data.

Load balancing: You can use a load balancer to distribute traffic across multiple instances or servers. 
For example, you can use an Application Load Balancer or Network Load Balancer in AWS to distribute traffic across multiple instances.

Monitoring and alerting: You should monitor your infrastructure for performance issues and set up alerts to notify you when
thresholds are reached. For example, you can use Amazon CloudWatch to monitor your application's metrics and 
set up alarms to notify you when the traffic exceeds a certain threshold.

Optimizing code and database queries: You can optimize your code and database queries to improve the performance of your application. 
For example, you can use tools such as AWS X-Ray to identify performance bottlenecks in your application and optimize them.

Overall, maintaining availability and performance during a surge in traffic requires careful planning and monitoring. 
By using the above techniques, you can ensure that your application can handle the increased traffic and provide a good user experience.

========================================================================================================================================
  86 * why we have to use SSL certificate 

SSL (Secure Sockets Layer) certificates are used to secure online communication by encrypting data sent between a user's
 web browser and a website's server. Here are some reasons why SSL certificates are important:

Protects sensitive information: SSL certificates encrypt data such as credit card numbers, login credentials, 
and other sensitive information, making it difficult for hackers to intercept and read the data.

Builds trust with website visitors: When a website has an SSL certificate, it shows a padlock icon in the browser's address bar,
 indicating that the website is secure. This builds trust with website visitors and helps to protect your brand reputation.

Boosts SEO: Search engines such as Google consider SSL certificates when ranking websites. 
Websites with SSL certificates are ranked higher than those without, which can increase visibility and drive more traffic to your website.

Meets compliance requirements: SSL certificates are often required by industry regulations, 
such as PCI DSS (Payment Card Industry Data Security Standard) for websites that process credit card payments.

Overall, SSL certificates are an essential tool for protecting sensitive information, building trust with website visitors, 
and meeting compliance requirements

============================================================================================================================================

  87 * dynamoDB











============================================================================================================================================

88 * vpc architecture ---duplicate
=============================================================================================================================================
  89 * why we need ELB & how you select which type of loadbalancer suitable for my application.

ELB (Elastic Load Balancing) is a service provided by Amazon Web Services (AWS) that helps distribute incoming traffic across multiple targets, 
such as EC2 instances, containers, or IP addresses. Here are some reasons why you might need an ELB:

High availability: By distributing traffic across multiple targets, 
an ELB helps ensure that your application remains available even if one or more targets fail.

Scalability: As your application grows, an ELB can automatically scale up or down to handle increased traffic.

Security: ELB can help protect your application from Distributed Denial of Service (DDoS) attacks by filtering out malicious traffic.

Improved performance: By distributing traffic based on various factors such as geographic location, protocol, 
or application-specific rules, an ELB can help improve the performance of your application.

When selecting which type of load balancer is suitable for your application, you need to consider the following factors:

Type of traffic: Different types of load balancers are designed for different types of traffic.
	 For example, if your application requires SSL/TLS termination, you would need an Application Load Balancer (ALB), whereas if you need to balance TCP/UDP traffic, you would need a Network Load Balancer (NLB).

Routing requirements: Different types of load balancers have different routing capabilities. 
	If you need to route traffic based on content-based routing, you would need an ALB, 
	whereas if you need to route traffic based on IP protocol, you would need an NLB.

Cost: Different types of load balancers have different pricing structures. For example, NLBs are generally more expensive than ALBs.

Load balancing algorithms: Different types of load balancers have different load balancing algorithms.
	 For example, ALBs use round-robin or weighted round-robin, whereas NLBs use a flow-based load balancing algorithm.

In summary, when selecting which type of load balancer is suitable for your application, 
you need to consider the type of traffic, routing requirements, cost, and load balancing algorithms. 
It's also a good idea to consult with a cloud architect or AWS certified professional to help you make the right choice.

============================================================================================================================================

90 * crosszone Loadbalancer -- duplicate

============================================================================================================================================
  91 * cloudwatch & cloudtrail -- duplicate
===========================================================================================================================================
 
 92 * Suppose you have ur dns in one server example xyz.com and one more asdf.com in another computer server 
	how your server xyz.com knows asdf.com also your how you do that
















============================================================================================================================================
  93 * Vpc --duplicate


  94 * Public subnet private subnet --duplicate
  95 * Cloudtrail -- duplicate
==================================================================================================================================
  96 * If we have like 100 servers in that 1-2 server failing how do you find out which one is failing
  97 * Best practices for securing Ur aws
  98 * how do you configure ec2 for high availability 
  99 * what are options aws provide for highly availiable ec2 if get trouble in one environment 
  100* what are different configuration used for do autoscalling
  101* how do you ensure that multi AZ configuration
  102* how can we connect s3 through vpc privetly
  103* how can we execute round robin waited routing of route53
  104* how can you search for particular error in K8s cloudwatch
  105* Apln load balancer :
  106* User data ,meta data
  107* Listener target 
  108* Cross zone load balancing 
  109* Application load balancer , classic network; disable ,pricing
  110* Bucket policy , access control 
  111* Autoscaling ,cloud watch alarm ,;predictive
  112* Cool down period (waits)
  113* Default encryption algo is base 64 
  114* Ingress ,loadbalancer
  115* Stateful sets ,static ip
  116* Have you used INSTANA?
  117* agroCD
  118* AWS glue?
  119* Servicemesh?
  120* SQL vs No SQL
  121* In aws, i have an instance which is critical machine that cant go down and its reaching 100% cpu utilisation.
  122* what are the steps that u r going to take to save this machine from going down?
  123* I have a ec2 instance, I want to change the private ip of that instance, can I do that?
  124* Can I change the private ip of running ec2 instance?
  125* I have a S3 bucket which my client want to track the access for internal audit.
  126* How can I track the access on my S3 bucket?
  127* For what purpose cloudtrail is used?
  128* I have an instance n db connected to this instance is on prem. how can I connect my application to on prem database.
  129* How will u connect aws with on prem database?
  130* nacl & security group
  131* nacl will be having inbound & outbound.. is it any configuration have to do manually
  132* traffic flow from NAT gateway to IGW
  133* traffic flow how cross NACL, SECURITY GROUP, NAT gateway 
  134* Why NAT gateway why  we cant NAT instance?
  135*  In aws, i have an instance which is critical machine that cant go down and its reaching 100% cpu utilisation.
  136* what are the steps that u r going to take to save this machine from going down?
  137* where u involved in the production release of ur application? are u deploying any application
  138* what is the deployment strategy that is used in ur company and other stratgies that u know?
  139* How you will spin up VPC
  140* How you were using cloudwatch
  141* Services used in AWS ?
  142* How can you make any S3 bucket as private ?
  143* Cross region replication ? how you apply it ? will it copy automatically ?
  144* S3 transfer accereration ?
  145* Read replica ?
  146* Suppose I have 1 master and 2 replicas, master crashes and what will happen to replication ?
  147* In case there is only one master and fails, application runs or failure ?
  148* Suppose you create Auto scaling group and in launch conf you specify as 3 instances, then the all the 3 instances are running in full capacity ? will the applciation fails or  it will be running ? Do you think AWS will provide new instance ?
  149* How to you manage credentials ?
  150* If credentials icon is not available? What you will do?
  151* You are working on EC2 and that goes down and how do you resolve this ?
  152* You want to give a access to a EC2 and you have only pvt key and how do you enable him to access the EC2 ?
  153* steps to spin up EC2 instance on linux server
  154* why Loadbalancer required
  155* where you are storing your application in cloud
  156* have you setup master & slave in jenkins? why slave machine required
  157* cloud watch
  158* do you have experience in lambda function & use case of lambda
  159* when its advicable to use vpc endpoint or IGW
  160* we have deploy an application in EC2 so i want to block few http ip address
  161* have experience with docker images. you deployed into AWS?
  162* tell me  about lambda syncronous and asyncronous using word configuration.
  163* how to create static website in s3
  164* what are the use cases you used in s3
  165* what are the use case of lambda. how you have used in your company
  166* explain complete setup of VPC how you are configure
  167* s3 is general, why we have to go for cross region. 
  168* Difference between public subnet and private subnet
  169* What is ENI
  170* How to connect two vpc
  171* How to upload files to S3 bucket
  172* How do you give access to S3 buckets
  173* Different kinds of load balancer
  174* Difference between alb n nlb
  175* Difference between TCP and UDP
  176* terraform for AWS lambda
  177* S3 encryption
  178* how other team member access S3
  179* how u have used IAM
  180* how encryption takes place in S3 for the team user operating on S3.
  181* cloudwatch vs cloudtrail
  182* Cost analysis for AWS services.
  183* Which are the AWS services that you have used?
  184* Waht are the limitaions of SNS services?
  185* How you monitor unhealthy instance using cloud watch?
  186* NAT gateway?
  187* Router?
  188* subnetmask? which one has more ip values 24 or 25? 
  189* How to configure autoscaling not to happen too rapidly?
  190* AWS- vpc , ebs and s3 diff
  191* Lamda function how u used in project
  192* Ec2 trouble shooting if u r not able to login 
  193* EKS
  194* Which region ur applications are hosted - tell atleast two regions 
  195* Which region kubernetes cluster set up
  196* CDN in AWS- cloud front
  197* In real time examples for cloud front
  198* Have you deployed any application to S3 bucket.
  199* What kind of data stored in s3 bucket- dynamic or static
  200* Types of servers used : app and web server Configuration details for jboss server

	If I understand your question correctly, you are asking about the configuration details for a JBoss server that is being used as an application server in an architecture that includes an Application Load Balancer (ALB) and web server. Here are some configuration details you may want to consider:

Operating System: The JBoss server can run on various operating systems such as Windows, Linux, and Unix. Choose the operating system based on your specific requirements and expertise.

Java Version: JBoss requires a Java Development Kit (JDK) to run. Make sure to install the required version of JDK that is compatible with your JBoss server version.

JBoss Installation: Download the latest version of JBoss from the official website and follow the installation instructions to install it on the server.

Configuration Files: JBoss uses various configuration files such as standalone.xml, domain.xml, and host.xml to configure the server. Configure these files based on your specific requirements.

Ports: JBoss uses various ports for different purposes such as HTTP, HTTPS, JMS, and JMX. Make sure to configure the ports correctly and ensure that they are accessible through the firewall.

Load Balancer Configuration: Configure the ALB to distribute traffic evenly among the JBoss instances. You can also configure session stickiness if required.

Web Server Configuration: If you are using a web server such as Apache or Nginx in front of JBoss, configure it to forward traffic to the ALB.

These are some of the basic configuration details you need to consider when setting up a JBoss server in an architecture that includes an ALB and web server. The specific configuration details may vary depending on your specific requirements and the version of JBoss you are using.
		
  201* ALB 
  202* Target groups and autoscaling groups and difference betn them
	
Target groups are used with Application Load Balancers (ALBs) and Network Load Balancers (NLBs) to route traffic to specific targets such as EC2 instances or containers. Target groups define the set of targets that the load balancer can route traffic to. When you create a target group, you specify the protocol and port that the load balancer uses to communicate with the targets. You can also specify health check settings to determine the health of the targets.

Auto scaling groups, on the other hand, are used to automatically scale EC2 instances based on demand. An auto scaling group consists of a collection of EC2 instances that are launched based on a specific set of policies. When the demand for resources increases, the auto scaling group automatically launches new instances to meet the demand. Similarly, when the demand decreases, the auto scaling group terminates instances to save costs.

The main difference between target groups and auto scaling groups is their purpose. Target groups are used for load balancing traffic to specific targets, while auto scaling groups are used for automatically scaling the number of EC2 instances based on demand. However, they can be used together to create a scalable and fault-tolerant architecture. For example, you can use an auto scaling group to launch EC2 instances and add them to a target group for load balancing traffic.





  203* Diff betn subnet and security group 
  204* AWS fargate 
  205* Single thread in AWS lambda
  206* what is SNS used for?
  207* Can we check disk space n usage from cloud watch ?
  208* In general section ec2, they have separate section on CPU credits, what are CPU credits on ec2?
  209* There are 2 major classification of ec2s, that is shared and dedicated. What is the diff between them?
  210* VPC peering
  211* VPC endpoints
  212* How you monitor complete e commerce website
  213* How you provide authentication and authorisation for users using your e commerce website
  214* What are the services you used in AWS
  215* How monitoring using promotheus and grafana works
  216* How you will give access using Iam to a user who wants to access only Jenkins master
  217* how do u configure cloudfront
  218* You are building a solution for a customer to extend their on-premises data center to AWS.
  219* The customer requires a 50-Mbps dedicated and private connection to their VPC. Which
  220* AWS product or feature satisfies this requirement?
  221* Which DNS name can only be resolved within Amazon EC2?
  222* What does Amazon CloudFormation provide?
  223* diffrence between the cloudformation and terraform
  224* have you deployed in diffrent regions ? how many availability zone ur using for application? why excatly those azs only
  225* distastive recovery in aws ?
  226* how to protect the aws through disaster
  227* if you have diffrent aws account how you will do the deployment? multi region deployment?
  228* how using route 53 route the traffoc to diffrent regions
  229* how your created vpc , how many type of subnets u have in compnay? 
  230* how will acess the database from the public subnet
  231* what are the nacl rules u have allowed for your application?
  232* what are the ports you have used for accesing data base for your application?
  233* how access the database like mysql , how you will define the port for database? how you will do that
  234* where will you define the port?
  235* how you will protect your system so that no one can acess the system?
  236* how do ypu check how much memory is consumed once you configure the autoscaling ? where will be logs stored 
  237* how ur acess the api gateway ? diffrence between load balancer and api gateway
  238* how do we pass the credentials for api gateway? how do we pass for web browser?
  239* how do you check the cloud watch logs through ec2 instance ? how do you check ?
  240* how to check the logs of application in ec2?
  241* if the logs size reaches the maximum capacity how ur going to manage, snapshot and ami are not the solution how you do it
  242* how do you mount the ebs volume permanantly
  243* aws cloundFront 
  244* diff between EKS and ECS
  245* s3 storage classes and diff bw standard and glacier storage class
  246* types of ELB
  247* how will check when you are unable connect to ec2 instance from your local system 
